---
title: "spacemen trees"
author: "Domingo Salerno"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include = F}
knitr::opts_chunk$set(echo = T)
set.seed(1)
```
```{r packages, include = F}
pacman::p_load(boot, bootstrap, car, glmnet, ISLR, leaps, MASS, neuralnet, pls, randomForest, tidyverse, tree)
```
```{r data, include = F}
data.raw <- read_csv("./data/star_classification.csv")

# clean data
data <- data.raw %>%
  select(14, 4:8, 15) %>%
  mutate(class = as.factor(class)) %>%
  subset(u > min(u))

# # scale predictor variables
# data.sc <- as_tibble(scale(data[ , 2:7]))
# data.sc <- tibble(data.sc)
# data.sc <- tibble("class" = data$class, data.sc)

# create validation sets
n <- nrow(data)
z <- sample(n, n * 0.9)
```



## Trees


### Single Tree

```{r VS pruned tree}
# train model and plot
tree <- tree(class ~ ., data[z, ])
y_hat <- predict(tree, newdata = data[-z, ], type = 'class')
plot(tree, type = 'uniform'); text(tree)

# show performance on testing data
(tree.err <- mean(y_hat != data[-z, ]$class))
table(y_hat, data[-z, ]$class)
```

```{r K-fold pruned tree}
# train model and plot
tree <- tree(class ~ ., data)
tree.cv <- cv.tree(tree, FUN = prune.misclass)
tree.cv.size <- tree.cv$size[which.min(tree.cv$dev)]
tree.pruned <- prune.misclass(tree, best = tree.cv.size)
plot(tree.pruned, type = 'uniform'); text(tree.pruned)

# show performance of model
tree.pruned.s <- summary(tree.pruned)
(tree.pruned.err <- tree.pruned.s[[7]][1] / tree.pruned.s[[7]][2])
```


### Random Forests

```{r VS random forest}
# initialize error and tree number variables
rf.err <- 0
ntrees <- 0
for(i in 1:5){
  rf <- randomForest(class ~ ., data = data[z, ], mtry = i)
  rf.ntrees <- which.min(rf$err.rate)
  rf <- randomForest(class ~ ., data = data[z, ], mtry = i, ntree = rf.ntrees)
  y_hat <- predict(rf, newdata = data[-z, ])
  rf.err[i] <- mean(y_hat != data[-z, ]$class)
  ntrees[i] <- rf.ntrees
}

plot(rf.err): lines(rf.err)

rf.optimal <- randomForest(class ~ ., data = data[z, ],
                           mtry = which.min(rf.err), 
                           ntrees = ntrees[which.min(rf.err)]
                           )
y_hat <- predict(rf.optimal, newdata = data[-z, ], type = 'class')
table(y_hat, data[-z, ]$class)
(rf.optimal.err <- mean(y_hat != data[-z, ]$class))
```



## Neural Network

```{r}
nn <- neuralnet(class ~ ., data = data.sc[z, ], hidden = c(10, 3), 
                stepmax = 1000, linear.output = F, rep = 10
                )
```

