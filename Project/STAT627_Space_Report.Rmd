---
title: "STAT-627 Space: KNN 2"
author: "Max Calzada, Josiah Gottfried, Sanghyeob Ko, Domingo Salerno"
date: '2022-12-03'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(class)
library(data.table)
library(dplyr)
library(pls)
library(tidyr)
library(tidyverse)
```

# Introduction

For our project, our central question was "Which statistical model would most optimally classify whether a celestial body is a star, quasar, or galaxy."

To answer this question we built the following models:

KNN
LDA/QDA
Logistic Regression
PCA
Trees/Random Forests

## Data

The data consists of 100,000 observations of space taken by the SDSS (Sloan Digital Sky Survey). Every observation is 
described by 17 feature columns and 1 class column which identifies it to be either a star, galaxy or quasar.

<https://www.kaggle.com/datasets/fedesoriano/stellar-classification-dataset-sdss17>

# Models

## KNN

```{r}
setwd("~/Desktop/STAT-627/STAT627_Space_Project")

Space_DF <- read.csv("star_classification.csv")
Space_DF <- Space_DF[, c("class", "u", "r", "g", "i", "z", "redshift")]
Space_DF$class_f <- as.factor(Space_DF$class) # Class or Factor? Why?
```

```{r}
set.seed(1)
n.S <- nrow(Space_DF) 
Z.S <- sample(n.S, n.S*0.9) # Weâ€™ll split data at random 
```

```{r}
S.Train <- Space_DF[Z.S,] # training data
S.Test <- Space_DF[-Z.S,] # testing data

X.S.Train <- S.Train[, c("u", "r", "g", "i", "z", "redshift")]
X.S.Test <- S.Test[, c("u", "r", "g", "i", "z", "redshift")]
Y.S.Train <- Space_DF$class_f[Z.S]
Y.S.Test <- Space_DF$class_f[-Z.S]
```

```{r}
knn.S = knn(X.S.Train, X.S.Test, Y.S.Train, 3) # K = 3?
table(Y.S.Test, knn.S)
```

```{r}
mean(Y.S.Test == knn.S )
```

```{r}
class.rate = rep(0,20) # Create a vector of length 20 and fill it with classification rates,
# which number instead of 20?
```

```{r}
for (K in 1:20) {
  knn.S = knn(X.S.Train, X.S.Test, Y.S.Train, K)
  class.rate[K] = mean(Y.S.Test == knn.S)
}

class.rate
```

```{r}
which.max(class.rate)
max(class.rate)
```

```{r}
# K20 <- as.vector(1:20)
# plot(K,class.rate)
plot(class.rate)
```

## LDA/QDA

## Logistic Regression

## PCA

```{r}
setwd("~/Desktop/STAT-627/STAT627_Space_Project")

Space_DF <- read.csv("star_classification.csv")
Space_DF <- Space_DF[, c("class", "u", "r", "g", "i", "z", "redshift")]

Space_DF <- Space_DF %>%
  mutate(class = as.factor(class)) %>%
  subset(u > min(u))
# Space_DF$class_f <- as.factor(Space_DF$class)
```

```{r}
X.pca = model.matrix(class ~ u + r + g + i + z + redshift, data = Space_DF)[,-1]
pc = prcomp(X.pca, scale = TRUE)
summary(pc)
screeplot(pc)
```

## Trees/Random Forests

# Results

The model with the best prediction rate was the random forest model at 97.76% accuracy.
